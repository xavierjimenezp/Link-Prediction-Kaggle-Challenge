{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhGtlA7RYYpV"
      },
      "source": [
        "<center><h2>ALTEGRAD Project</h2>\n",
        "\n",
        "<hr>\n",
        "<span style=\"font-variant: small-caps;\">Xavier Jiménez, Jean Quentin, Sacha Revol</span><br>\n",
        "<hr>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1FMzZfeYMgQ"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCeqWnCtUBiW",
        "outputId": "1caa3353-4986-4b40-e960-35483c5c1a34"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import randint\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import log_loss\n",
        "# import nltk\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import string\n",
        "from tqdm import tqdm\n",
        "\n",
        "# !pip install pip install karateclub\n",
        "from gensim.models.doc2vec import Doc2Vec\n",
        "from os import path\n",
        "import pickle\n",
        "from scipy import spatial\n",
        "import random\n",
        "from sklearn import preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load preprocessed files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These files are created in `Preprocessing.ipynb`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Authors preprocessed\n"
          ]
        }
      ],
      "source": [
        "# Read the abstract of each paper\n",
        "try:\n",
        "    print('Loading Authors preprocessed')\n",
        "    a_file = open(\"data/authors_preprocessed.pkl\", \"rb\")\n",
        "    authors = pickle.load(a_file)\n",
        "    a_file.close()\n",
        "except:\n",
        "    raise SyntaxError(\"File 'authors_preprocessed.pkl' was not found in 'data/'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5j-YMepW46s",
        "outputId": "ec1883d8-fac2-423c-eb09-3e747c18f393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load abstract preprocessed\n"
          ]
        }
      ],
      "source": [
        "# Read the abstract of each paper\n",
        "try:\n",
        "    print('Load abstract preprocessed')\n",
        "    a_file = open(\"data/abstract_preprocessed.pkl\", \"rb\")\n",
        "    abstracts = pickle.load(a_file)\n",
        "    a_file.close()\n",
        "except:\n",
        "    raise SyntaxError(\"File 'abstract_preprocessed.pkl' was not found in 'data/'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5LbuWc0eF6U"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(X_train, X_test, y_train, y_test = None, model = LogisticRegression(max_iter = 300)):\n",
        "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "    \n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict_proba(X_test)\n",
        "    y_pred = y_pred[:,1]\n",
        "    if y_test is not None:\n",
        "        print('Validation loss = {:.4f}'.format(log_loss(y_test, y_pred)))\n",
        "    else:\n",
        "        # Write predictions to a file\n",
        "        print('Creating submission')\n",
        "        predictions = zip(range(len(y_pred)), y_pred)\n",
        "        os.remove(\"data/submission.csv\")\n",
        "        with open(\"data/submission.csv\",\"w\") as pred:\n",
        "            csv_out = csv.writer(pred)\n",
        "            csv_out.writerow(['id','predicted'])\n",
        "            for row in predictions:\n",
        "                csv_out.writerow(row)\n",
        "        print('Submision created')\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature matrix creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Common functions for matrix creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_random_edges_from_G(p = 0.05, seed = 1):\n",
        "    \"\"\"Removes p lines from edgelist randomly and saves\n",
        "    remaining lines as edgelist_missing.txt\n",
        "\n",
        "    Args:\n",
        "        p (float, optional): line percentage to be removed. Defaults to 0.05.\n",
        "        seed (int, optional): seed for random. Defaults to 1.\n",
        "    \"\"\"\n",
        "\n",
        "    H = nx.read_edgelist('data/edgelist.txt', delimiter=',', create_using=nx.Graph(), nodetype=int)\n",
        "    with open('data/edgelist.txt') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    random.seed(seed)\n",
        "    indices_to_delete = random.sample(range(len(lines)), int(p * len(lines)))\n",
        "\n",
        "    # sort to delete biggest index first \n",
        "    indices_to_delete.sort(reverse=True)\n",
        "\n",
        "    for i in tqdm(indices_to_delete):\n",
        "        line = lines[i]\n",
        "        t = line.split(',')\n",
        "        H.remove_edge(int(t[0]), int(t[1]))\n",
        "        \n",
        "    return H"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_info(G, p = 0.05, validation = True):\n",
        "    \"\"\"This function returns validation/test node pairs list and\n",
        "    validation/test + train random nodes that will be used to create\n",
        "    feature matrix. These lists have a fixed seed.\n",
        "\n",
        "    Args:\n",
        "        G (Networkx graph): A Graph loaded with NetworkX library.\n",
        "        p (float, optional): Percentage of edges removed from G to create validation Graph H.\n",
        "        See 'Preprocessing.ipynb' to see which value was used. Defaults to 0.05.\n",
        "        validation (bool, optional): If True, will return validation lists.\n",
        "        Else, will return test lists. Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        lists: validation/test node pairs list and validation/test + \n",
        "               train random nodes\n",
        "    \"\"\"\n",
        "        \n",
        "    np.random.seed(41)\n",
        "    train_random_nodes = np.random.choice(list(G.nodes()), size=2*len(G.edges()), replace=True)\n",
        "        \n",
        "    if validation:\n",
        "        val_node_pairs = list()\n",
        "        with open('data/edgelist.txt') as file:\n",
        "            lines = file.readlines()\n",
        "\n",
        "        random.seed(42)\n",
        "        indices_to_delete = random.sample(range(len(lines)), int(p * len(lines)))\n",
        "        indices_to_delete.sort(reverse=True)\n",
        "\n",
        "        for i in tqdm(indices_to_delete):\n",
        "            line = lines[i]\n",
        "            t = line.split(',')\n",
        "            val_node_pairs.append((int(t[0]), int(t[1])))\n",
        "        np.random.seed(42)\n",
        "        val_random_nodes = np.random.choice(list(G.nodes()), size=2*len(val_node_pairs), replace=True)\n",
        "        \n",
        "        return val_node_pairs, val_random_nodes, train_random_nodes\n",
        "        \n",
        "\n",
        "    else:\n",
        "        test_node_pairs = list()\n",
        "        with open('data/test.txt', 'r') as f:\n",
        "            for line in f:\n",
        "                t = line.split(',')\n",
        "                test_node_pairs.append((int(t[0]), int(t[1])))\n",
        "                \n",
        "        np.random.seed(43)\n",
        "        test_random_nodes = np.random.choice(list(G.nodes()), size=len(test_node_pairs), replace=True)\n",
        "        \n",
        "        return test_node_pairs, test_random_nodes, train_random_nodes\n",
        "    \n",
        "def graph_properties(G):\n",
        "    \"\"\"Computes standard Graph properties with NetworkX\n",
        "    Args:\n",
        "        G ([nx graph)\n",
        "    Returns:\n",
        "        list of arrays, each array contains individual property \n",
        "        for each node.\n",
        "    \"\"\"\n",
        "    \n",
        "    print('Computing graph properties')\n",
        "    avg_neighbor_degree = nx.average_neighbor_degree(G)\n",
        "    pagerank = nx.pagerank_scipy(G)\n",
        "    # eig_centrality = nx.eigenvector_centrality_numpy(G)\n",
        "    # greedy_color = nx.greedy_color(G)\n",
        "    # triangles = nx.triangles(G)\n",
        "\n",
        "    return [avg_neighbor_degree, pagerank]#, eig_centrality, greedy_color, triangles]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Default matrix creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_default_matrix(G, validation = True):\n",
        "    \"\"\"Creates feature matrix with baseline features. \n",
        "\n",
        "    Args:\n",
        "        G (NetworkX Graph): A Graph loaded with NetworkX library.\n",
        "        validation (bool, optional): If True, will return validation lists.\n",
        "        Else, will return test lists. Defaults to True.\n",
        "    \"\"\"\n",
        "\n",
        "    n_features = 6\n",
        "    \n",
        "    if validation:\n",
        "        val_node_pairs, val_random_nodes, train_random_nodes = load_info(G, validation = validation)\n",
        "        X_val = np.zeros((2*len(val_node_pairs), n_features))\n",
        "        y_val = np.zeros(2*len(val_node_pairs))\n",
        "        \n",
        "    else:\n",
        "        test_node_pairs, test_random_nodes, train_random_nodes = load_info(G, validation = validation)\n",
        "        X_test = np.zeros((len(test_node_pairs), n_features))\n",
        "                  \n",
        "    X_train = np.zeros((2*len(G.edges()), n_features))\n",
        "    y_train = np.zeros(2*len(G.edges()))\n",
        "    \n",
        "    \n",
        "    \n",
        "    for i, train_edge in tqdm(enumerate(G.edges())):\n",
        "        X_train, y_train = fill_default_matrix(i, 2, G, X_train, y_train, train_edge, train_random_nodes)\n",
        "    np.save('data/X_train_default.npy', X_train)\n",
        "    np.save('data/y_train', y_train)\n",
        "    if validation:\n",
        "        for i, val_edge in tqdm(enumerate(val_node_pairs)):\n",
        "            X_val, y_val = fill_default_matrix(i, 2, G, X_val, y_val, val_edge, val_random_nodes)\n",
        "        np.save('data/X_val_default.npy', X_val)\n",
        "        np.save('data/y_val', y_val)\n",
        "    else:\n",
        "        for i, test_edge in tqdm(enumerate(test_node_pairs)):\n",
        "            X_test = fill_default_matrix(i, 1, G, X_test, None, test_edge, test_random_nodes)\n",
        "        np.save('data/X_test_default.npy', X_test)\n",
        "        \n",
        "        \n",
        "def fill_default_matrix(i, p, G, X, y, edge, random_nodes):\n",
        "    \"\"\"Fills each line of the default feature matrix.\n",
        "\n",
        "    Args:\n",
        "        i (int): matrix line.\n",
        "        p (int): If p=1, creates test matrix. If p=2, creates either train or validation.\n",
        "        G (nx graph): Graph loaded with NetworkX.\n",
        "        X (np.ndarray): Shape (2 x n_edges, n_features)\n",
        "        y (np.ndarray): Shape (2 x n_edges, ). Set to None for test.\n",
        "        edge (list): list of tupple of nodes.\n",
        "        random_nodes (list): list of random nodes. Shape (2 x n_edges, ).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: if p=1, returns X, y filled. Elif p=2, returns X filled.\n",
        "    \"\"\"\n",
        "    X[p*i,0] = len(abstracts[edge[0]]) + len(abstracts[edge[1]])\n",
        "    X[p*i,1] = abs(len(abstracts[edge[0]]) - len(abstracts[edge[1]]))\n",
        "    X[p*i,2] = len(set(abstracts[edge[0]]).intersection(set(abstracts[edge[1]])))\n",
        "    try:\n",
        "        X[p*i,3] = G.degree(edge[0]) + G.degree(edge[1])\n",
        "        X[p*i,4] = abs(G.degree(edge[0]) - G.degree(edge[1]))\n",
        "    except:\n",
        "        X[p*i,3] = -1\n",
        "        X[p*i,4] = -1\n",
        "    X[p*i,5] = len(set(authors[edge[0]]).intersection(set(authors[edge[1]])))\n",
        "    \n",
        "    \n",
        "    if p == 2:\n",
        "        y[2*i] = 1\n",
        "\n",
        "        n1, n2 = random_nodes[2*i], random_nodes[2*i+1]\n",
        "            \n",
        "        X[2*i+1,0] = len(abstracts[n1]) + len(abstracts[n2])\n",
        "        X[2*i+1,1] = abs(len(abstracts[n1]) - len(abstracts[n2]))\n",
        "        X[2*i+1,2] = len(set(abstracts[n1]).intersection(set(abstracts[n2])))\n",
        "        X[2*i+1,3] = G.degree(n1) + G.degree(n2)\n",
        "        X[2*i+1,4] = abs(G.degree(n1) - G.degree(n2))\n",
        "        X[2*i+1,5] = len(set(authors[n1]).intersection(set(abstracts[n2])))\n",
        "\n",
        "        y[2*i+1] = 0\n",
        "\n",
        "        return X, y\n",
        "    else:\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Param matrix creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_param_matrix(G, validation = True):\n",
        "    \"\"\"Creates Graph parameters feature matrix. \n",
        "\n",
        "    Args:\n",
        "        G (NetworkX Graph): A Graph loaded with NetworkX library.\n",
        "        validation (bool, optional): If True, will return validation lists.\n",
        "        Else, will return test lists. Defaults to True.\n",
        "    \"\"\"\n",
        "\n",
        "    G_params = graph_properties(G)\n",
        "    n_features = len(G_params)\n",
        "    \n",
        "    if validation:\n",
        "        val_node_pairs, val_random_nodes, train_random_nodes = load_info(G, validation = validation)\n",
        "        X_val = np.zeros((2*len(val_node_pairs), n_features))\n",
        "        y_val = np.zeros(2*len(val_node_pairs))\n",
        "        \n",
        "    else:\n",
        "        test_node_pairs, test_random_nodes, train_random_nodes = load_info(G, validation = validation)\n",
        "        X_test = np.zeros((len(test_node_pairs), n_features))\n",
        "                  \n",
        "    X_train = np.zeros((2*len(G.edges()), n_features))\n",
        "    y_train = np.zeros(2*len(G.edges()))\n",
        "    \n",
        "    \n",
        "    \n",
        "    for i, train_edge in tqdm(enumerate(G.edges())):\n",
        "        X_train, y_train = fill_param_matrix(i, 2, G, X_train, y_train, train_edge, train_random_nodes, G_params)\n",
        "    np.save('data/X_train_param', X_train)\n",
        "    np.save('data/y_train', y_train)\n",
        "    if validation:\n",
        "        for i, val_edge in tqdm(enumerate(val_node_pairs)):\n",
        "            X_val, y_val = fill_param_matrix(i, 2, G, X_val, y_val, val_edge, val_random_nodes, G_params)\n",
        "        np.save('data/X_val_param', X_val)\n",
        "        np.save('data/y_val', y_val)\n",
        "    else:\n",
        "        for i, test_edge in tqdm(enumerate(test_node_pairs)):\n",
        "            X_test = fill_param_matrix(i, 1, G, X_test, None, test_edge, test_random_nodes, G_params)\n",
        "        np.save('data/X_test_param.npy', X_test)\n",
        "        \n",
        "        \n",
        "def fill_param_matrix(i, p, G, X, y, edge, random_nodes, G_params):\n",
        "    \"\"\"Fills each line of the Graph parameters feature matrix.\n",
        "\n",
        "    Args:\n",
        "        i (int): matrix line.\n",
        "        p (int): If p=1, creates test matrix. If p=2, creates either train or validation.\n",
        "        G (nx graph): Graph loaded with NetworkX.\n",
        "        X (np.ndarray): Shape (2 x n_edges, n_features)\n",
        "        y (np.ndarray): Shape (2 x n_edges, ). Set to None for test.\n",
        "        edge (list): list of tupple of nodes.\n",
        "        random_nodes (list): list of random nodes. Shape (2 x n_edges, ).\n",
        "        G_params (list): list containing graph parameters.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: if p=1, returns X, y filled. Elif p=2, returns X filled.\n",
        "    \"\"\"\n",
        "    \n",
        "    for idx, j in enumerate(range(len(G_params) + 1, 2)):\n",
        "        param = G_params[idx]\n",
        "        try:\n",
        "            X[p*i,j] = param[edge[0]] + param[edge[1]]\n",
        "            X[p*i,j+1] = abs(param[edge[0]] - param[edge[1]])\n",
        "        except:\n",
        "            X[p*i,j] = -1\n",
        "            X[p*i,j+1] = -1\n",
        "    \n",
        "    \n",
        "    if p == 2:\n",
        "        y[2*i] = 1\n",
        "        y[2*i+1] = 0\n",
        "        n1, n2 = random_nodes[2*i], random_nodes[2*i+1]\n",
        "            \n",
        "        for idx, j in enumerate(range(len(G_params) + 1, 2)):\n",
        "            param = G_params[idx]\n",
        "            X[2*i+1,j] = param[n1] + param[n2]\n",
        "            X[2*i+1,j+1] = abs(param[n1] - param[n2])\n",
        "\n",
        "        return X, y\n",
        "    else:\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Embedding Matrix creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_embeddings_matrix(G, distance, validation = True):\n",
        "    \"\"\"Creates Graph embeddings feature matrix. \n",
        "\n",
        "    Args:\n",
        "        G (NetworkX Graph): A Graph loaded with NetworkX library.\n",
        "        distance (scipy spatial distance): Function that takes two 1d arrays\n",
        "        and outputs a float. Recommended: cosine distance.\n",
        "        validation (bool, optional): If True, will return validation lists.\n",
        "        Else, will return test lists. Defaults to True.\n",
        "    \"\"\"\n",
        "    \n",
        "    n2v_parameters = {'walk_number': 10, 'walk_length': 15, 'dimensions': 64, 'window_size': 5}\n",
        "    d2v_parameters = {'vector_size':128, 'window':5, 'min_count':2, 'epochs':100}\n",
        "    walkets_parameters = {'walk_number': 10, 'walk_length': 80, 'dimensions': 64, 'window_size': 4}\n",
        "    \n",
        "    d2v = Doc2Vec.load(\"data/abstracts_embedding_doc2vec_vs{:d}_w{:d}_mc{:d}_e{:d}\".format(d2v_parameters['vector_size'], d2v_parameters['window'],\n",
        "                                                                            d2v_parameters['min_count'], d2v_parameters['epochs']))\n",
        "    \n",
        "    # authors_emb = np.load('data/embedding_authors_articles_mean.npy')\n",
        "    embeddings = [d2v]#, authors_emb]\n",
        "    \n",
        "    \n",
        "    if validation:\n",
        "        n2v = np.load('data/embedding_n2v_val_wn{:d}_wl{:d}_d{:d}_ws{:d}.npy'.format(n2v_parameters['walk_number'], n2v_parameters['walk_length'],\n",
        "                                                                n2v_parameters['dimensions'], n2v_parameters['window_size']))\n",
        "        embeddings.append(n2v)\n",
        "        n_features = len(embeddings)\n",
        "        \n",
        "        val_node_pairs, val_random_nodes, train_random_nodes = load_info(G, validation = validation)\n",
        "        X_val = np.zeros((2*len(val_node_pairs), n_features))\n",
        "        y_val = np.zeros(2*len(val_node_pairs))\n",
        "        \n",
        "        \n",
        "\n",
        "    else:\n",
        "        n2v = np.load('data/embedding_n2v_wn{:d}_wl{:d}_d{:d}_ws{:d}.npy'.format(n2v_parameters['walk_number'], n2v_parameters['walk_length'],\n",
        "                                                                n2v_parameters['dimensions'], n2v_parameters['window_size']))\n",
        "        walkets = np.load('data/embedding_Walklets_wn{:d}_wl{:d}_d{:d}_ws{:d}.npy'.format(walkets_parameters['walk_number'], walkets_parameters['walk_length'],\n",
        "                                                                walkets_parameters['dimensions'], walkets_parameters['window_size']))\n",
        "        embeddings.append(n2v)\n",
        "        embeddings.append(walkets)\n",
        "        n_features = len(embeddings)\n",
        "        \n",
        "        test_node_pairs, test_random_nodes, train_random_nodes = load_info(G, validation = validation)\n",
        "        X_test = np.zeros((len(test_node_pairs), n_features))\n",
        "          \n",
        "    X_train = np.zeros((2*len(G.edges()), n_features))\n",
        "    y_train = np.zeros(2*len(G.edges()))\n",
        "    \n",
        "    \n",
        "    \n",
        "    for i, train_edge in tqdm(enumerate(G.edges())):\n",
        "        X_train, y_train = fill_embeddings_matrix(i, 2, X_train, y_train, train_edge, train_random_nodes, embeddings, distance)\n",
        "    np.save('data/X_train_embeddings', X_train)\n",
        "    np.save('data/y_train', y_train)\n",
        "    if validation:\n",
        "        for i, val_edge in tqdm(enumerate(val_node_pairs)):\n",
        "            X_val, y_val = fill_embeddings_matrix(i, 2, X_val, y_val, val_edge, val_random_nodes, embeddings, distance)\n",
        "        np.save('data/X_val_embeddings', X_val)\n",
        "        np.save('data/y_val', y_val)\n",
        "    else:\n",
        "        for i, test_edge in tqdm(enumerate(test_node_pairs)):\n",
        "            X_test = fill_embeddings_matrix(i, 1, X_test, None, test_edge, test_random_nodes, embeddings, distance)\n",
        "        np.save('data/X_test_embeddings', X_test)\n",
        "          \n",
        "            \n",
        "def fill_embeddings_matrix(i, p, X, y, edge, random_nodes, embeddings, distance):\n",
        "    \"\"\"Fills each line of the Graph embedding feature matrix.\n",
        "\n",
        "    Args:\n",
        "        i (int): matrix line.\n",
        "        p (int): If p=1, creates test matrix. If p=2, creates either train or validation.\n",
        "        G (nx graph): Graph loaded with NetworkX.\n",
        "        X (np.ndarray): Shape (2 x n_edges, n_features)\n",
        "        y (np.ndarray): Shape (2 x n_edges, ). Set to None for test.\n",
        "        edge (list): list of tupple of nodes.\n",
        "        random_nodes (list): list of random nodes. Shape (2 x n_edges, ).\n",
        "        embeddings (list): list of np.ndarrays containing embeddings for each node in the Graph\n",
        "        distance (scipy spatial distance): Function that takes two 1d arrays\n",
        "        and outputs a float. Recommended: cosine distance.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: if p=1, returns X, y filled. Elif p=2, returns X filled.\n",
        "    \"\"\"\n",
        "\n",
        "    for j, emb in enumerate(embeddings):\n",
        "        if j == 0:\n",
        "            X[p*i,j] = emb.dv.similarity(edge[0], edge[1])\n",
        "        else:\n",
        "            X[p*i,j] = distance(emb[edge[0]], emb[edge[1]])\n",
        "    \n",
        "    # X[p*i,8] = distance(gae.iloc[edge[0]].to_numpy(), gae.iloc[edge[1]].to_numpy())\n",
        "      \n",
        "    if p == 2:\n",
        "        y[2*i] = 1\n",
        "        y[2*i+1] = 0\n",
        "        n1, n2 = random_nodes[2*i], random_nodes[2*i+1]        \n",
        "        for j, emb in enumerate(embeddings):\n",
        "            if j == 0:\n",
        "                X[2*i+1,j] = emb.dv.similarity(n1, n2)\n",
        "            else:\n",
        "                X[2*i+1,j] = distance(emb[n1], emb[n2])\n",
        "    \n",
        "        # X[2*i+1,8] = distance(gae.iloc[n1].to_numpy(), gae.iloc[n2].to_numpy())\n",
        "\n",
        "\n",
        "        return X, y\n",
        "    else:\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def nodes_connected(G, u, v):\n",
        "#     return u in G.neighbors(v)\n",
        "# neighbor = nx.single_source_shortest_path_length(H, 0, cutoff=2)\n",
        "# # neighbor = {v: k for k, v in neighbor.items()}\n",
        "# embe = np.load('data/embedding_authors_articles_mean.npy')\n",
        "\n",
        "# for i in list(neighbor.keys())[1:10]:\n",
        "#     # print(embe[i,:10])\n",
        "#     # print(embe[0,:10])\n",
        "#     if nodes_connected(H, i, 1):\n",
        "#         print('Connected {:d}-{:d}: {:.2f}'.format(i, 0, spatial.distance.cosine(embe[i], embe[0])))\n",
        "#     else:\n",
        "#         print('Not Connected {:d}-{:d}: {:.2f}'.format(i, 0, spatial.distance.cosine(embe[i], embe[0])))\n",
        "        \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Other features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_new_feature_matrix(G, measures, validation = True):\n",
        "    n_features = len(measures)\n",
        "    \n",
        "    X_train = np.zeros((2*len(G.edges()), n_features))\n",
        "    y_train = np.zeros(2*len(G.edges()))\n",
        "    \n",
        "    if validation:\n",
        "        val_node_pairs, val_random_nodes, train_random_nodes = load_info(G, validation = validation)\n",
        "        X_val = np.zeros((2*len(val_node_pairs), n_features))\n",
        "        y_val = np.zeros(2*len(val_node_pairs))\n",
        "    else:\n",
        "        test_node_pairs, test_random_nodes, train_random_nodes = load_info(G, validation = validation)\n",
        "        X_test = np.zeros((len(test_node_pairs), n_features))\n",
        "        \n",
        "    for i, train_edge in tqdm(enumerate(G.edges())):\n",
        "        X_train, y_train = fill_new_feature_matrix(i, 2, G, X_train, y_train, train_edge, train_random_nodes, measures)\n",
        "    np.save('data/X_train_new_features', X_train)\n",
        "    \n",
        "    if validation:\n",
        "        for i, val_edge in tqdm(enumerate(val_node_pairs)):\n",
        "            X_val, y_val = fill_new_feature_matrix(i, 2, G, X_val, y_val, val_edge, val_random_nodes, measures)\n",
        "        np.save('data/X_val_new_features', X_val)\n",
        "        return X_train, X_val, y_train, y_val\n",
        "\n",
        "    else:\n",
        "        for i, test_edge in tqdm(enumerate(test_node_pairs)):\n",
        "            X_test = fill_new_feature_matrix(i, 1, G, X_test, None, test_edge, test_random_nodes, measures)\n",
        "        np.save('data/X_test_new_features', X_test)\n",
        "        return X_train, X_test, y_train\n",
        "        \n",
        "        \n",
        "def fill_new_feature_matrix(i, p, G, X, y, edge, random_nodes, measures):\n",
        "    for j, measure in enumerate(measures):\n",
        "        X[p*i,j] = measure(edge[0], edge[1], G)\n",
        "    \n",
        "    if p == 2:\n",
        "        y[2*i] = 1\n",
        "        y[2*i+1] = 0\n",
        "        n1, n2 = random_nodes[2*i], random_nodes[2*i+1]\n",
        "        for j, measure in enumerate(measures):\n",
        "            X[2*i+1,j] = measure(n1, n2, G)\n",
        "\n",
        "        return X, y\n",
        "    else:\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Matrix concatenation & loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def concatenate_matrix(default = True, param = True, embeddings = True, new_feature = True, validation = True):\n",
        "    bool_list = [default, param, embeddings, new_feature]\n",
        "    X_train_default = np.load('data/X_train_default.npy')\n",
        "    X_train_param = np.load('data/X_train_param.npy')\n",
        "    X_train_embeddings = np.load('data/X_train_embeddings.npy')\n",
        "    X_train_new_feature = np.load('data/X_train_new_features.npy')\n",
        "    print(X_train_default.shape, X_train_param.shape, X_train_embeddings.shape, X_train_new_feature.shape)\n",
        "    X_train_list = [X for i,X in enumerate([X_train_default, X_train_param, X_train_embeddings, X_train_new_feature]) if bool_list[i]]\n",
        "    X_train = np.concatenate(X_train_list, axis=1)\n",
        "    np.save('data/X_train', X_train)\n",
        "    y_train = np.load('data/y_train.npy')\n",
        "    if validation:\n",
        "        X_val_default = np.load('data/X_val_default.npy')\n",
        "        X_val_param = np.load('data/X_val_param.npy')\n",
        "        X_val_embeddings = np.load('data/X_val_embeddings.npy')\n",
        "        X_val_new_feature = np.load('data/X_val_new_features.npy')\n",
        "        X_val_list = [X for i,X in enumerate([X_val_default, X_val_param, X_val_embeddings, X_val_new_feature]) if bool_list[i]]\n",
        "        X_val = np.concatenate(X_val_list, axis=1)\n",
        "        np.save('data/X_val', X_val)\n",
        "        y_val = np.load('data/y_val.npy')\n",
        "        return X_train, X_val, y_train, y_val\n",
        "    else:\n",
        "        X_test_default = np.load('data/X_test_default.npy')\n",
        "        X_test_param = np.load('data/X_test_param.npy')\n",
        "        X_test_embeddings = np.load('data/X_test_embeddings.npy')\n",
        "        X_test_new_feature = np.load('data/X_test_new_features.npy')\n",
        "        X_test_list = [X for i,X in enumerate([X_test_default, X_test_param, X_test_embeddings, X_test_new_feature]) if bool_list[i]]\n",
        "        X_test = np.concatenate(X_test_list, axis=1)\n",
        "        np.save('data/X_test', X_test)\n",
        "        return X_train, X_test, y_train\n",
        "\n",
        "def load_matrix(validation = True):\n",
        "    X_train = np.load('data/X_train.npy')\n",
        "    y_train = np.load('data/y_train.npy')\n",
        "    if validation:\n",
        "        X_val = np.load('data/X_val.npy')\n",
        "        y_val = np.load('data/y_val.npy')\n",
        "        return X_train, X_val, y_train, y_val\n",
        "    else:\n",
        "        X_test = np.load('data/X_test.npy')\n",
        "        return X_train, X_test, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions to add/remove new features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_new_feature(G, measure, distance, validation = True):\n",
        "    n_features = 1\n",
        "    \n",
        "    X_train = np.zeros((2*len(G.edges()), n_features))\n",
        "    y_train = np.zeros(2*len(G.edges()))\n",
        "    \n",
        "    if validation:\n",
        "        val_node_pairs, val_random_nodes, train_random_nodes = load_info(G, validation = validation)\n",
        "        X_val = np.zeros((2*len(val_node_pairs), n_features))\n",
        "        y_val = np.zeros(2*len(val_node_pairs))\n",
        "    else:\n",
        "        test_node_pairs, test_random_nodes, train_random_nodes = load_info(G, validation = validation)\n",
        "        X_test = np.zeros((len(test_node_pairs), n_features))\n",
        "        \n",
        "    for i, train_edge in tqdm(enumerate(G.edges())):\n",
        "        X_train, y_train = fill_new_feature(i, 2, G, X_train, y_train, train_edge, train_random_nodes, distance, measure)\n",
        "    X_train_full = np.load('data/X_train.npy')\n",
        "    \n",
        "    if validation:\n",
        "        for i, val_edge in tqdm(enumerate(val_node_pairs)):\n",
        "            X_val, y_val = fill_new_feature(i, 2, G, X_val, y_val, val_edge, val_random_nodes, distance, measure)\n",
        "        X_val_full = np.load('data/X_val.npy')\n",
        "        return np.concatenate((X_train_full, X_train), axis=1), np.concatenate((X_val_full, X_val), axis=1), y_train, y_val\n",
        "\n",
        "    else:\n",
        "        for i, test_edge in tqdm(enumerate(test_node_pairs)):\n",
        "            X_test = fill_new_feature(i, 1, G, X_test, None, test_edge, test_random_nodes, distance, measure)\n",
        "        X_test_full = np.load('data/X_test.npy')\n",
        "        return np.concatenate((X_train_full, X_train), axis=1), np.concatenate((X_test_full, X_test), axis=1), y_train\n",
        "        \n",
        "        \n",
        "def fill_new_feature(i, p, G, X, y, edge, random_nodes, distance, measure):\n",
        "    try:\n",
        "        X[p*i,0] = measure(edge[0], edge[1], G, distance)\n",
        "    except:\n",
        "        X[p*i,0] = -1\n",
        "    \n",
        "    if p == 2:\n",
        "        y[2*i] = 1\n",
        "        y[2*i+1] = 0\n",
        "        n1, n2 = random_nodes[2*i], random_nodes[2*i+1]\n",
        "        X[2*i+1,0] = measure(n1, n2, G, distance)\n",
        "\n",
        "        return X, y\n",
        "    else:\n",
        "        return X\n",
        "\n",
        "def remove_last_feature(X_train, X_test):\n",
        "    return X_train[:,:-1], X_test[:,:-1]\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measures for new features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def shortest_path_length(n1, n2, G, distance=None):\n",
        "    \"\"\"\n",
        "    Computes the shortest path length between two nodes in a graph.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        length = nx.shortest_path_length(G, n1, n2)\n",
        "    except:\n",
        "        length = -1\n",
        "    return length\n",
        "\n",
        "def dijkstra_path_length(n1, n2, G, distance=None):\n",
        "    \"\"\"\n",
        "    Computes the dijkstra path length between two nodes in a graph.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        length = nx.dijkstra_path_length(G, n1, n2)\n",
        "    except:\n",
        "        length = -1\n",
        "    return length\n",
        "\n",
        "def jaccard_coefficient(n1, n2, G, distance=None):\n",
        "    \"\"\"\n",
        "    Computes the jaccard coefficient of two nodes in a graph.\n",
        "    \"\"\"\n",
        "    _, _, coeff = list(nx.jaccard_coefficient(G, [(n1, n2)]))[0]\n",
        "    return coeff\n",
        "\n",
        "\n",
        "def adamic_adar_index(n1, n2, G, distance=None):\n",
        "    \"\"\"\n",
        "    Computes the adamic adar index of two nodes in a graph.\n",
        "    \"\"\"\n",
        "    _, _, index = list(nx.adamic_adar_index(G, [(n1, n2)]))[0]\n",
        "    return index\n",
        "\n",
        "\n",
        "def pref_attachment(n1, n2, G, distance=None):\n",
        "    \"\"\" \n",
        "    Computes the preferential attachment of two nodes in a graph.\n",
        "    \"\"\"\n",
        "    _, _, p = list(nx.preferential_attachment(G, [(n1, n2)]))[0]\n",
        "    return p\n",
        "\n",
        "def common_neighbor_centrality(n1, n2, G, distance=None):\n",
        "    \"\"\" \n",
        "    Computes the common neighbor centrality of two nodes in a graph.\n",
        "    \"\"\"\n",
        "    _, _, p = nx.common_neighbor_centrality(G, [(n1, n2)])\n",
        "    return p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "common_neighbor_centrality(1, 0, G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Validation matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For validation, all parameters including embeddings should be computed using the validation graph. Results should be computed again on the full graph to submit a test result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    # Validation Graph computed in Preprocessing.ipynb\n",
        "    H = nx.read_edgelist('data/edgelist_val.txt', delimiter=',', create_using=nx.Graph(), nodetype=int)\n",
        "except:\n",
        "    raise SyntaxError(\"File 'edgelist_val.txt' was not found in 'data/'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Matrix creation/loading and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 54597/54597 [00:00<00:00, 471885.13it/s]\n",
            "1037358it [01:00, 17079.54it/s]\n",
            "54597it [00:03, 15805.04it/s]\n"
          ]
        }
      ],
      "source": [
        "create_default_matrix(H, validation = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing graph properties\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 54597/54597 [00:00<00:00, 421319.50it/s]\n",
            "1037358it [00:02, 399113.24it/s]\n",
            "54597it [00:00, 372396.70it/s]\n"
          ]
        }
      ],
      "source": [
        "create_param_matrix(H, validation = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 54597/54597 [00:00<00:00, 391935.28it/s]\n",
            "1037358it [04:39, 3715.33it/s]\n",
            "54597it [00:13, 4077.65it/s]\n"
          ]
        }
      ],
      "source": [
        "# BAD: chebyshev, braycurtis, canberra, euclidian, jaccard\n",
        "# TO TEST: cityblock, correlation, jensenshannon, mahalanobis, minkowski, seuclidean, sqeuclidean, wminkowski, dice, hamming\n",
        "# BEST: cosine\n",
        "distance = spatial.distance.cosine #spatial.distance.cosine #euclidean_distance #\n",
        "create_embeddings_matrix(H, distance = distance, validation = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_new_feature_matrix(H, measures = [shortest_path_length], validation = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2074716, 6) (2074716, 2) (2074716, 2) (2074716, 1)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, y_train, y_val = concatenate_matrix(default = True, param = False, embeddings = True, new_feature = False, validation = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss = 0.2573\n"
          ]
        }
      ],
      "source": [
        "y_pred = train(X_train, X_val, y_train, y_val, model = LogisticRegression(max_iter = 300))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>157.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.783946</td>\n",
              "      <td>0.392490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>179.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.985746</td>\n",
              "      <td>1.093389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>193.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.680442</td>\n",
              "      <td>0.404881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>146.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.982158</td>\n",
              "      <td>0.964146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>182.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.603073</td>\n",
              "      <td>0.518883</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0     1     2     3     4    5         6         7\n",
              "0  157.0  15.0   2.0  21.0  17.0  1.0  0.783946  0.392490\n",
              "1  179.0  71.0   2.0  29.0  23.0  0.0  0.985746  1.093389\n",
              "2  193.0  21.0   7.0  41.0  37.0  0.0  0.680442  0.404881\n",
              "3  146.0  42.0   3.0  36.0  26.0  0.0  0.982158  0.964146\n",
              "4  182.0  40.0  10.0  30.0   8.0  0.0  0.603073  0.518883"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train = pd.DataFrame(data = X_train)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 54597/54597 [00:00<00:00, 557645.13it/s]\n",
            "1037358it [00:20, 51024.39it/s]\n",
            "54597it [00:01, 50387.24it/s]\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, y_train, y_val = add_new_feature(H, measure = pref_attachment, distance = None, validation = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss = 0.2573\n"
          ]
        }
      ],
      "source": [
        "y_pred = train(X_train, X_val, y_train, y_val, model = LogisticRegression(max_iter = 300))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_val = remove_last_feature(X_train, X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "G = nx.read_edgelist('data/edgelist.txt', delimiter=',', create_using=nx.Graph(), nodetype=int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Matrix creation/loading and submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1091955it [01:05, 16608.25it/s]\n",
            "106692it [00:02, 36626.16it/s]\n"
          ]
        }
      ],
      "source": [
        "create_default_matrix(G, validation = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing graph properties\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1091955it [00:02, 388125.64it/s]\n",
            "106692it [00:00, 1137894.63it/s]\n"
          ]
        }
      ],
      "source": [
        "create_param_matrix(G, validation = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]/tmp/ipykernel_3213/339881457.py:88: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
            "  X[p*i,j] = emb.docvecs.similarity(edge[0], edge[1])\n",
            "/tmp/ipykernel_3213/339881457.py:100: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
            "  X[2*i+1,j] = emb.docvecs.similarity(n1, n2)\n",
            "133534it [00:39, 3752.01it/s]"
          ]
        }
      ],
      "source": [
        "distance = spatial.distance.cosine #spatial.distance.cosine #euclidean_distance #\n",
        "create_embeddings_matrix(G, distance = distance, validation = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1091955it [00:21, 50492.42it/s]\n",
            "106692it [00:00, 109798.68it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([[ 40.],\n",
              "        [ 67.],\n",
              "        [ 78.],\n",
              "        ...,\n",
              "        [130.],\n",
              "        [  2.],\n",
              "        [301.]]),\n",
              " array([[1922.],\n",
              "        [ 126.],\n",
              "        [4096.],\n",
              "        ...,\n",
              "        [  45.],\n",
              "        [1221.],\n",
              "        [1008.]]),\n",
              " array([1., 0., 1., ..., 0., 1., 0.]))"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "create_new_feature_matrix(G, measures = [pref_attachment], validation = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2183910, 6) (2074716, 2) (2183910, 3) (2183910, 1)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train= concatenate_matrix(default = True, param = False, embeddings = True, new_feature = False, validation = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1091955it [11:05, 1640.69it/s]\n",
            "106692it [00:28, 3794.94it/s]\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train = add_new_feature(G, measure = shortest_path_length, distance = None, validation = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating submission\n",
            "Submision created\n"
          ]
        }
      ],
      "source": [
        "y_pred = train(X_train, X_test, y_train, y_test = None, model = LogisticRegression(max_iter = 300))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>157.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.783946</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.548589</td>\n",
              "      <td>0.248893</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>170.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.982963</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.948378</td>\n",
              "      <td>0.793439</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>193.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.680442</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.460406</td>\n",
              "      <td>0.253649</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>252.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.007298</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.969859</td>\n",
              "      <td>0.838834</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>182.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.603073</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.342701</td>\n",
              "      <td>0.206544</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0     1     2     3     4    5    6    7    8    9    10        11   12  \\\n",
              "0  157.0  15.0   2.0  22.0  18.0  1.0  0.0  0.0  0.0  0.0  0.0  0.783946  0.0   \n",
              "1  170.0  26.0   2.0  14.0   2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.982963  0.0   \n",
              "2  193.0  21.0   7.0  41.0  37.0  0.0  0.0  0.0  0.0  0.0  0.0  0.680442  0.0   \n",
              "3  252.0  72.0  11.0  19.0   5.0  0.0  0.0  0.0  0.0  0.0  0.0  1.007298  0.0   \n",
              "4  182.0  40.0  10.0  31.0   9.0  0.0  0.0  0.0  0.0  0.0  0.0  0.603073  0.0   \n",
              "\n",
              "         13        14   15  \n",
              "0  0.548589  0.248893  1.0  \n",
              "1  0.948378  0.793439  4.0  \n",
              "2  0.460406  0.253649  1.0  \n",
              "3  0.969859  0.838834  4.0  \n",
              "4  0.342701  0.206544  1.0  "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train = pd.DataFrame(data = X_train)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(138499, 256)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "walklets_parameters = {'walk_number': 10, 'walk_length': 80, 'dimensions': 64, 'window_size': 4}\n",
        "\n",
        "walklets = np.load('data/embedding_Walklets_wn{:d}_wl{:d}_d{:d}_ws{:d}.npy'.format(walklets_parameters['walk_number'], walklets_parameters['walk_length'],\n",
        "                                                                walklets_parameters['dimensions'], walklets_parameters['window_size']))\n",
        "walklets.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2.70029998, 2.70029998, 2.70029998, ..., 2.70029998, 2.70029998,\n",
              "        2.70029998],\n",
              "       [1.49200952, 1.49200952, 1.49200952, ..., 1.49200952, 1.49200952,\n",
              "        1.49200952],\n",
              "       [2.09158826, 2.09158826, 2.09158826, ..., 2.09158826, 2.09158826,\n",
              "        2.09158826],\n",
              "       ...,\n",
              "       [1.99976814, 1.99976814, 1.99976814, ..., 1.99976814, 1.99976814,\n",
              "        1.99976814],\n",
              "       [1.52823949, 1.52823949, 1.52823949, ..., 1.52823949, 1.52823949,\n",
              "        1.52823949],\n",
              "       [2.41397214, 2.41397214, 2.41397214, ..., 2.41397214, 2.41397214,\n",
              "        2.41397214]])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "authors_emb = np.load('data/embedding_authors_articles_mean.npy')\n",
        "authors_emb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Old"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing embedding properties and other ideas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected 0-0: 0.09, 4\n",
            "Connected 3-0: 0.59, 0\n",
            "Connected 5-0: 1.10, 0\n",
            "Connected 6-0: 0.65, 0\n",
            "Connected 7-0: 0.61, 0\n",
            "Connected 9-0: 0.69, 0\n",
            "Connected 10-0: 0.70, 1\n",
            "Connected 11-0: 0.54, 0\n",
            "Connected 12-0: 0.61, 0\n"
          ]
        }
      ],
      "source": [
        "d2v = Doc2Vec.load(\"data/abstracts_embedding_doc2vec_vs64_w5_mc2_e100\")\n",
        "\n",
        "neighbor = nx.single_source_shortest_path_length(G, 1, cutoff=3)\n",
        "# neighbor = {v: k for k, v in neighbor.items()}\n",
        "\n",
        "for i in list(neighbor.keys())[1:10]:\n",
        "    if nodes_connected(G, i, 1):\n",
        "        print('Connected {:d}-{:d}: {:.2f}, {:d}'.format(i, 0, spatial.distance.cosine(d2v[i], d2v[1]), len(authors[i].intersection(authors[0]))))\n",
        "    else:\n",
        "        print('Not Connected {:d}-{:d}: {:.2f}, {:d}'.format(i, 0, spatial.distance.cosine(d2v[i], d2v[1]), len(authors[i].intersection(authors[0]))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not Connected 57843-0: 1.05\n",
            "Not Connected 37538-0: 0.93\n",
            "Not Connected 65147-0: 0.87\n",
            "Not Connected 106678-0: 0.93\n",
            "Not Connected 18223-0: 0.95\n",
            "Not Connected 89973-0: 0.91\n",
            "Not Connected 125515-0: 0.95\n",
            "Not Connected 73222-0: 1.09\n",
            "Not Connected 64208-0: 0.99\n",
            "Not Connected 4594-0: 0.94\n",
            "Not Connected 19913-0: 0.95\n",
            "Not Connected 57703-0: 0.89\n",
            "Not Connected 23905-0: 0.99\n",
            "Not Connected 122321-0: 0.92\n",
            "Not Connected 9201-0: 1.02\n",
            "Not Connected 101385-0: 0.98\n",
            "Not Connected 61178-0: 0.75\n",
            "Not Connected 88102-0: 0.87\n",
            "Not Connected 111660-0: 0.78\n",
            "Not Connected 90555-0: 1.03\n"
          ]
        }
      ],
      "source": [
        "for i in range(0,20):\n",
        "    # random.seed(i)\n",
        "    k1 = randint(0, n-1)\n",
        "    k2 = randint(0, n-1)\n",
        "    if nodes_connected(G, k1, k2):\n",
        "        print('Connected {:d}-{:d}: {:.2f}'.format(k1, 0, spatial.distance.cosine(d2v[k1], d2v[k2])))\n",
        "    else:\n",
        "        print('Not Connected {:d}-{:d}: {:.2f}'.format(k2, 0, spatial.distance.cosine(d2v[k1], d2v[k2])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected 0-1: 0.09\n",
            "Connected 0-2: 0.86\n",
            "Connected 1-3: 0.59\n",
            "Connected 1-5: 1.10\n",
            "Connected 1-6: 0.65\n",
            "Connected 1-7: 0.61\n",
            "Connected 1-9: 0.69\n",
            "Connected 1-10: 0.70\n",
            "Connected 1-11: 0.54\n",
            "Connected 1-12: 0.61\n",
            "Connected 1-13: 0.58\n",
            "Connected 1-14: 0.59\n",
            "Connected 1-15: 0.67\n",
            "Connected 1-16: 0.66\n",
            "Connected 1-17: 0.84\n",
            "Connected 1-19: 1.00\n",
            "Connected 1-20: 0.66\n",
            "Connected 1-21: 0.74\n",
            "Connected 1-22: 0.60\n",
            "Connected 1-23: 0.61\n",
            "Connected 1-24: 0.72\n",
            "Connected 2-25: 0.82\n",
            "Connected 2-26: 0.91\n",
            "Connected 2-27: 0.99\n",
            "Connected 2-28: 1.00\n",
            "Connected 2-29: 0.99\n",
            "Connected 2-30: 1.05\n",
            "Connected 2-31: 1.04\n",
            "Connected 2-32: 0.87\n",
            "Connected 2-33: 0.92\n",
            "Connected 2-34: 0.93\n"
          ]
        }
      ],
      "source": [
        "for i, edge in enumerate(G.edges()):\n",
        "    print('Connected {:d}-{:d}: {:.2f}'.format(edge[0], edge[1], spatial.distance.cosine(d2v[edge[0]], d2v[edge[1]])))\n",
        "    if i==30:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "20it [00:00, 4169.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "2\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for i,edge in tqdm(enumerate(G.edges())):\n",
        "    print(len(set(authors[edge[0]]).intersection(set(authors[edge[1]]))))\n",
        "    # cos_distance = spatial.distance.cosine(d2v[edge[0]], d2v[edge[1]])\n",
        "    # print(cos_distance)\n",
        "   \n",
        "    if i == 20:\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ALTEGRAD_project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
